{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueTransforms = ['gaussianblur_1',\n",
    " 'gaussianblur_10',\n",
    " 'gaussianblur_20',\n",
    " 'superpixels_0p1',\n",
    " 'superpixels_0p5',\n",
    " 'superpixels_0p85',\n",
    " 'colorspace_25',\n",
    " 'colorspace_50',\n",
    " 'averageblur_5_11',\n",
    " 'medianblur_1',\n",
    " 'sharpen_0',\n",
    " 'sharpen_1',\n",
    " 'sharpen_2',\n",
    " 'addintensity_-80',\n",
    " 'addintensity_80',\n",
    " 'elementrandomintensity_1',\n",
    " 'multiplyintensity_0p25',\n",
    " 'multiplyintensity_2',\n",
    " 'contrastnormalization_0',\n",
    " 'contrastnormalization_1',\n",
    " 'contrastnormalization_2',\n",
    " 'elastic_1',\n",
    " 'invert']\n",
    "spaceTransforms2 = ['scaled_1p25',\n",
    " 'scaled_0p75',\n",
    " 'scaled_0p5',\n",
    " 'scaled_(1p25, 1p0)',\n",
    " 'scaled_(0p75, 1p0)',\n",
    " 'scaled_(1p0, 1p25)',\n",
    " 'scaled_(1p0, 0p75)',\n",
    " 'translate_(0p1, 0p1)',\n",
    " 'translate_(0p1, -0p1)',\n",
    " 'translate_(-0p1, 0p1)',\n",
    " 'translate_(-0p1, -0p1)',\n",
    " 'translate_(0p1, 0)',\n",
    " 'translate_(-0p1, 0)',\n",
    " 'translate_(0, 0p1)',\n",
    " 'translate_(0, -0p1)',\n",
    " 'rotated_3',\n",
    " 'rotated_5',\n",
    " 'rotated_10',\n",
    " 'rotated_45',\n",
    " 'rotated_60',\n",
    " 'rotated_90',\n",
    " 'flipH',\n",
    " 'flipV',\n",
    " 'dropout',\n",
    " 'piecewiseAffine_0p01',#\n",
    " 'piecewiseAffine_0p03',#\n",
    " 'piecewiseAffine_0p06',#\n",
    " 'piecewiseAffine_0p1']#\n",
    "len(spaceTransforms2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Space transforms\n",
    "spaceTransforms = {}\n",
    "# Change image scale keeping aspect ratio same ( same scaling of width and height)\n",
    "for r in [1.25,.75,.5]:\n",
    "    spaceTransforms['scaled_' + str(r).replace('.','p')] = iaa.Sequential([\n",
    "        iaa.Affine(scale=r)\n",
    "    ])\n",
    "# Change image scale not keeping aspect ratio same ( unequal scaling of width and height)\n",
    "for r in [(1.25,1.0), (.75,1.0), (1.0,1.25), (1.0,.75)]:#125% or 75% of one of the dimensions\n",
    "    spaceTransforms['scaled_' + str(r).replace('.','p')]=iaa.Sequential([\n",
    "        iaa.Affine(scale={\"x\": r[0], \"y\": r[1]})\n",
    "    ])\n",
    "    \n",
    "# translate image by +-10% towards each of corners(diagonally) or edges(horizontally and vertically)\n",
    "for tr in [(.1,.1), (.1,-.1), (-.1,.1), (-.1,-.1), (.1,0), (-.1,0), (0,.1), (0,-.1)]:\n",
    "    spaceTransforms['translate_' + str(tr).replace('.','p')]=iaa.Sequential([\n",
    "        iaa.Affine(translate_percent={\"x\":tr[0], \"y\":tr[1]})\n",
    "    ])\n",
    "    \n",
    "# Change orientation by few small angles and few large angles\n",
    "for theta in [3,5,10,45,60,90]:\n",
    "    spaceTransforms['rotated_' + str(theta).replace('.','p')]=iaa.Sequential([\n",
    "        iaa.Affine(rotate=theta)\n",
    "    ])\n",
    "    \n",
    "# Flip images horizontly\n",
    "for _ in [1]:\n",
    "    spaceTransforms['flipH']=iaa.Sequential([\n",
    "        iaa.Fliplr(1.0)\n",
    "    ])\n",
    "    \n",
    "# Flip images vertically\n",
    "for _ in [1]:\n",
    "    spaceTransforms['flipV']=iaa.Sequential([\n",
    "        iaa.Flipud(1.0)\n",
    "    ])\n",
    "# Random pixel dropout, 10% of pixels, like salt and pepper noise without salt\n",
    "for _ in [1]:\n",
    "    spaceTransforms['dropout'] = iaa.Sequential([\n",
    "        iaa.Dropout(p=0.1)\n",
    "    ])\n",
    "# Good local distortions, Refer at http://imgaug.readthedocs.io/en/latest/source/augmenters.html#piecewiseaffine\n",
    "#for z in [0.01,0.03,0.06,0.1]:\n",
    "#    spaceTransforms['piecewiseAffine_'+str(z).replace('.','p')]=iaa.Sequential([\n",
    "#        iaa.PiecewiseAffine(scale=z)\n",
    "#    ])\n",
    "len(spaceTransforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Files to read\n",
    "models = ['e2e_faster_rcnn_R-50-C4_2x',\n",
    "'e2e_faster_rcnn_R-50-FPN_2x',\n",
    "'e2e_faster_rcnn_R-101-FPN_2x',\n",
    "'e2e_faster_rcnn_X-101-64x4d-FPN_2x',\n",
    "'e2e_mask_rcnn_R-50-C4_2x',\n",
    "'e2e_mask_rcnn_R-50-FPN_2x',\n",
    "'e2e_mask_rcnn_R-101-FPN_2x',\n",
    "'retinanet_R-50-FPN_2x',\n",
    "'retinanet_R-101-FPN_2x',\n",
    "'retinanet_X-101-64x4d-FPN_2x']\n",
    "dataF = 'G:/edu/sem2/766/proj/ML_OD_Benchmarking/data/'\n",
    "outputs = dataF+'outputs/'\n",
    "\n",
    "resF = outputs +'5000_original_results/'\n",
    "tranF = outputs + 'transformed_outputs/'\n",
    "spaceF = outputs + 'transformed_spatial_output/'\n",
    "newResF = outputs +'5000_original_results_matches/'\n",
    "newTranF = outputs + 'transformed_outputs_matches/'\n",
    "newSpaceF = outputs + 'transformed_spatial_output_matches/'\n",
    "#create new directories\n",
    "pathsV = [newTranF+_+'/' for _ in valueTransforms]\n",
    "pathsS = [newSpaceF+_+'/' for _ in spaceTransforms]\n",
    "for path in [newResF]+pathsV+pathsS:\n",
    "    for algo in models:\n",
    "        directory = os.path.dirname(path+algo+'/')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "#COCO annotations file\n",
    "anntF = dataF+'inputs/annotations/instances_val2017.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.71s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "cocoGt=COCO(anntF)\n",
    "#cocoDt=cocoGt.loadRes(origF+algoF + '0_e2e_faster_rcnn_R-50-C4_2x.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28193.59970</td>\n",
       "      <td>[126.72, 18.22, 381.43, 218.56]</td>\n",
       "      <td>28</td>\n",
       "      <td>283003</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[318.49, 26.22, 318.49, 18.78, 321.24, 18.22,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>882.09260</td>\n",
       "      <td>[0.24, 156.89, 28.77, 66.78]</td>\n",
       "      <td>28</td>\n",
       "      <td>284085</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.42, 156.89, 6.39, 160.33, 13.09, 165.58, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13106.33585</td>\n",
       "      <td>[307.06, 271.55, 131.45, 154.49]</td>\n",
       "      <td>1</td>\n",
       "      <td>1230651</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[430.84, 420.28, 307.06, 426.04, 313.77, 366....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14034.33930</td>\n",
       "      <td>[176.56, 274.43, 134.33, 147.77]</td>\n",
       "      <td>1</td>\n",
       "      <td>1255402</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[308.02, 421.24, 180.4, 422.2, 176.56, 397.25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9113.10595</td>\n",
       "      <td>[534.53, 310.58, 104.76, 115.51]</td>\n",
       "      <td>1</td>\n",
       "      <td>1277571</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[556.56, 379.35, 552.8, 370.75, 550.65, 365.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7465.50055</td>\n",
       "      <td>[0.25, 142.7, 54.64, 244.7]</td>\n",
       "      <td>1</td>\n",
       "      <td>1282917</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[10.13, 236.28, 10.71, 214.19, 14.78, 194.43,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16278.32565</td>\n",
       "      <td>[139.45, 165.9, 111.56, 255.81]</td>\n",
       "      <td>1</td>\n",
       "      <td>1697952</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[178.88, 171.67, 165.41, 187.05, 163.49, 204....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5668.68900</td>\n",
       "      <td>[396.17, 283.41, 69.27, 143.59]</td>\n",
       "      <td>1</td>\n",
       "      <td>1700528</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[396.17, 319.32, 400.28, 312.65, 400.28, 303....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>491.92805</td>\n",
       "      <td>[141.2, 187.23, 20.89, 37.98]</td>\n",
       "      <td>1</td>\n",
       "      <td>1702706</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[151.33, 225.21, 159.56, 210.65, 162.09, 212....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15130.11685</td>\n",
       "      <td>[265.8, 145.85, 151.6, 218.78]</td>\n",
       "      <td>1</td>\n",
       "      <td>1704618</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[293.62, 303.22, 265.8, 264.84, 270.59, 247.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22845.02495</td>\n",
       "      <td>[41.12, 162.37, 109.65, 262.52]</td>\n",
       "      <td>1</td>\n",
       "      <td>1754082</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[41.12, 423.84, 89.62, 424.89, 130.74, 424.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>383.59340</td>\n",
       "      <td>[123.31, 205.1, 19.29, 35.11]</td>\n",
       "      <td>1</td>\n",
       "      <td>1762066</td>\n",
       "      <td>530162</td>\n",
       "      <td>0</td>\n",
       "      <td>[[123.31, 207.11, 125.33, 206.25, 129.64, 206....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           area                              bbox  category_id       id  \\\n",
       "0   28193.59970   [126.72, 18.22, 381.43, 218.56]           28   283003   \n",
       "1     882.09260      [0.24, 156.89, 28.77, 66.78]           28   284085   \n",
       "2   13106.33585  [307.06, 271.55, 131.45, 154.49]            1  1230651   \n",
       "3   14034.33930  [176.56, 274.43, 134.33, 147.77]            1  1255402   \n",
       "4    9113.10595  [534.53, 310.58, 104.76, 115.51]            1  1277571   \n",
       "5    7465.50055       [0.25, 142.7, 54.64, 244.7]            1  1282917   \n",
       "6   16278.32565   [139.45, 165.9, 111.56, 255.81]            1  1697952   \n",
       "7    5668.68900   [396.17, 283.41, 69.27, 143.59]            1  1700528   \n",
       "8     491.92805     [141.2, 187.23, 20.89, 37.98]            1  1702706   \n",
       "9   15130.11685    [265.8, 145.85, 151.6, 218.78]            1  1704618   \n",
       "10  22845.02495   [41.12, 162.37, 109.65, 262.52]            1  1754082   \n",
       "11    383.59340     [123.31, 205.1, 19.29, 35.11]            1  1762066   \n",
       "\n",
       "    image_id  iscrowd                                       segmentation  \n",
       "0     530162        0  [[318.49, 26.22, 318.49, 18.78, 321.24, 18.22,...  \n",
       "1     530162        0  [[0.42, 156.89, 6.39, 160.33, 13.09, 165.58, 1...  \n",
       "2     530162        0  [[430.84, 420.28, 307.06, 426.04, 313.77, 366....  \n",
       "3     530162        0  [[308.02, 421.24, 180.4, 422.2, 176.56, 397.25...  \n",
       "4     530162        0  [[556.56, 379.35, 552.8, 370.75, 550.65, 365.3...  \n",
       "5     530162        0  [[10.13, 236.28, 10.71, 214.19, 14.78, 194.43,...  \n",
       "6     530162        0  [[178.88, 171.67, 165.41, 187.05, 163.49, 204....  \n",
       "7     530162        0  [[396.17, 319.32, 400.28, 312.65, 400.28, 303....  \n",
       "8     530162        0  [[151.33, 225.21, 159.56, 210.65, 162.09, 212....  \n",
       "9     530162        0  [[293.62, 303.22, 265.8, 264.84, 270.59, 247.5...  \n",
       "10    530162        0  [[41.12, 423.84, 89.62, 424.89, 130.74, 424.89...  \n",
       "11    530162        0  [[123.31, 207.11, 125.33, 206.25, 129.64, 206....  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imgIds = cocoGt.getImgIds()\n",
    "annIds = cocoGt.getAnnIds(imgIds = [530162])\n",
    "anns = cocoGt.loadAnns(annIds)\n",
    "dt = pd.DataFrame(anns)\n",
    "dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16314116498247844"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bbMatch(A,B, base = 'union'):\n",
    "    '''Returns a Jaccard like score of match between the two bounding boxes. IntersectionArea / BaseArea'''\n",
    "    areaA = A[2]*A[3]#First object's area\n",
    "    areaB = B[2]*B[3]#Second objects area\n",
    "    #print(areaU)\n",
    "    if areaA==0 or areaB ==0:\n",
    "        return 0#avoid division by zero when no match\n",
    "    if B[2]<0 or B[3]<0:\n",
    "        print('less than zero ', B)\n",
    "    xa1,ya1,xa2,ya2 = A[0],A[1],A[0]+A[2], A[1]+A[3]\n",
    "    xb1,yb1,xb2,yb2 = B[0],B[1],B[0]+B[2], B[1]+B[3]\n",
    "    dx = min(xa2, xb2) - max(xa1, xb1)#overlap in x\n",
    "    dy = min(ya2, yb2) - max(ya1, yb1)#overlap in y\n",
    "    areaI= dx*dy if (dx>=0) and (dy>=0) else 0\n",
    "    #Possible base areas\n",
    "    area = {'first':   areaA,\n",
    "            'second':  areaB,\n",
    "            'sum':     areaA+areaB,\n",
    "            'union':   areaA+areaB-areaI,#union = sum - intersection\n",
    "            'larger':  areaA if areaA>areaB else areaB,\n",
    "            'smaller': areaA if areaA<areaB else areaB}\n",
    "    \n",
    "    return areaI/area[base];\n",
    "A = [415.11, 204.57, 172.01, 258.54]\n",
    "B = [423.078522, 205.677017, 580.738586, 441.871582]\n",
    "bbMatch(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findMatchingBBoxes(detectedJsons, cocoAnnotations,outDir,algo):\n",
    "    '''loopes over all images in detected Jsons.\n",
    "    For each object in these images, finds the best matching object\n",
    "    provided in coco Annotations for this particular image.\n",
    "    Match is done by comparing overlapping area (Jaccard measure) of the two bounding boxes.\n",
    "    Must match atleast 10%.\n",
    "    Also creates a new json file that is more structured'''\n",
    "    #outputs = []\n",
    "    for i, js in enumerate(detectedJsons):#multiple json files returned by glob\n",
    "        #print(js)\n",
    "        if i>0:#for now to save time read only one file. Remove in actual script or parallelize\n",
    "            break\n",
    "        with open(js) as fd:\n",
    "            imgs = json.load(fd)#go over each file\n",
    "        outputs = []#[None]*len(imgs)\n",
    "        for _idx,img in enumerate(imgs):#array of info\n",
    "            img_name = img['img_name'].split('/')[-1]\n",
    "            parts = img_name.split('__')\n",
    "            #print(parts)\n",
    "            if len(parts)==2:\n",
    "                transform = parts[0]\n",
    "                imgId = int(parts[1][:-4])\n",
    "                if 'piecewise' in transform:#skip all piecewise\n",
    "                    continue\n",
    "            else:\n",
    "                imgId = int(parts[0][:-4])\n",
    "                transform = None\n",
    "            detected = []\n",
    "            count = 0\n",
    "            uniques = set()\n",
    "            dt = pd.DataFrame(cocoAnnotations.loadAnns(cocoGt.getAnnIds(imgIds = [imgId])))\n",
    "            for index,A in enumerate(img['bboxes']):#for each object detected by NN\n",
    "                #reframe information to write in json\n",
    "                info ={'detClass':img['classes'][index],\n",
    "                            'detBbox':A,\n",
    "                            'score':img['scores'][index],\n",
    "                            'matchObjectId':None,\n",
    "                            'matchClass':None,\n",
    "                            'matchBBox':None,}\n",
    "                detected.append(info)\n",
    "                if img['scores'][index]<0.5:#skip objects with low confidence\n",
    "                    continue\n",
    "                best, bestM = None,-1\n",
    "                for _, obj in dt.iterrows():#go over all given annotations for this image\n",
    "                    B = obj.bbox\n",
    "                    #print(B, transform)\n",
    "                    if transform in spaceTransforms:#need to transform bbox and transform != 'dropout'\n",
    "                        bbs = ia.BoundingBoxesOnImage(#make from x,y,w,h\n",
    "                            [ia.BoundingBox(x1=B[0], y1=B[1], x2=B[0]+B[2], y2=B[1]+B[3])],\n",
    "                            shape=[cocoGt.imgs[imgId]['height'], cocoGt.imgs[imgId]['width']])\n",
    "                        T = spaceTransforms[transform]\n",
    "                        try:\n",
    "                            B = T.augment_bounding_boxes([bbs])[0].bounding_boxes[0]\n",
    "                            B = [B.x1, B.y1, B.x2-B.x1, B.y2-B.y1]\n",
    "                        except:\n",
    "                            print(B,transform)\n",
    "                            #B = obj.bbox\n",
    "                            continue\n",
    "                        #print(B)\n",
    "                    #Use larger as base of match, for better result as prevents saturation (match=1)\n",
    "                    m = bbMatch(A,B, 'larger')#find match between two objects' bboxes\n",
    "                    if m >=0.10 and m>bestM:#best of all matches with atleast 10% match\n",
    "                        best,bestM = obj,m#id defined by coco annotations\n",
    "                if not best is None:#preserve order\n",
    "                    info['matchObjectId']=best.id\n",
    "                    info['matchClass']=best.category_id\n",
    "                    info['matchBBox']=best.bbox\n",
    "                    uniques.add(best.id)\n",
    "                    count = count+1\n",
    "            #matchedBBoxes[str(imgId)] = matches\n",
    "            outputs.append({'image_id':imgId,\n",
    "                             'objects':detected,#all objects detected in this image\n",
    "                            'totalDetected': len(img['bboxes']),\n",
    "                            'matched':count,\n",
    "                            'uniqueMatches':len(uniques),\n",
    "                            'transform':transform})\n",
    "        #Divide results into separate transformations, once per json file\n",
    "        \n",
    "        dt = pd.DataFrame(outputs)\n",
    "        trsfms = dt['transform'].unique()\n",
    "        print(trsfms)\n",
    "        if len(trsfms) == 1 and trsfms[0] is None:#from orig 5000 results\n",
    "            path = outDir + algo+'/'+os.path.basename(js)\n",
    "            with open(path,'w') as fd:\n",
    "                #print(path)\n",
    "                fd.write(json.dumps(dt.to_dict('index')))\n",
    "        else:#a transformed result\n",
    "            for tr in trsfms:\n",
    "                path = outDir + tr + '/' + algo+'/'+os.path.basename(js)\n",
    "                with open(path,'w') as fd:\n",
    "                    #print(path)\n",
    "                    fd.write(json.dumps(dt[dt['transform']==tr].to_dict('index')))\n",
    "    #return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[208.2, 254.04, 5.61, 1.28] scaled_0p75\n",
      "[129.4, 52.38, 3.05, 1.53] scaled_0p5\n",
      "[129.4, 52.38, 3.05, 1.53] scaled_0p5\n",
      "[129.4, 52.38, 3.05, 1.53] scaled_0p5\n",
      "[129.4, 52.38, 3.05, 1.53] scaled_0p5\n",
      "[129.4, 52.38, 3.05, 1.53] scaled_0p5\n",
      "[129.4, 52.38, 3.05, 1.53] scaled_0p5\n",
      "['scaled_(0p75, 1p0)' 'scaled_0p5' 'translate_(-0p1, -0p1)'\n",
      " 'scaled_(1p25, 1p0)' 'rotated_5' 'translate_(-0p1, 0)' 'rotated_10'\n",
      " 'rotated_3' 'translate_(0, 0p1)' 'scaled_0p75' 'rotated_45' 'flipH'\n",
      " 'scaled_(1p0, 0p75)' 'rotated_60' 'flipV' 'dropout' 'translate_(0p1, 0)'\n",
      " 'translate_(0, -0p1)' 'translate_(0p1, 0p1)' 'translate_(0p1, -0p1)'\n",
      " 'translate_(-0p1, 0p1)' 'rotated_90' 'scaled_1p25' 'scaled_(1p0, 1p25)']\n"
     ]
    }
   ],
   "source": [
    "for algo in models[0:1]:\n",
    "    origJsons = glob.iglob(resF+algo + '/*.json')\n",
    "    #findMatchingBBoxes(origJsons, cocoGt,newResF,algo)\n",
    "    origJsons = glob.iglob(tranF+algo + '/*.json')\n",
    "    #findMatchingBBoxes(origJsons, cocoGt,newTranF,algo)\n",
    "    origJsons = glob.iglob(spaceF+algo + '/*.json')\n",
    "    #print(spaceF+algo)\n",
    "    findMatchingBBoxes(origJsons, cocoGt,newSpaceF,algo)\n",
    "\n",
    "#matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 0 100\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
